{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dPQDLn0HiIX9",
    "outputId": "3cc3e14d-46c9-4983-a05d-a6326ad029dc",
    "ExecuteTime": {
     "end_time": "2024-05-04T15:33:47.319794Z",
     "start_time": "2024-05-04T15:33:45.854390Z"
    }
   },
   "source": [
    "!pip install -q mediapipe"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;31merror\u001B[0m: \u001B[1mexternally-managed-environment\u001B[0m\r\n",
      "\r\n",
      "\u001B[31m×\u001B[0m This environment is externally managed\r\n",
      "\u001B[31m╰─>\u001B[0m To install Python packages system-wide, try 'pacman -S\r\n",
      "\u001B[31m   \u001B[0m python-xyz', where xyz is the package you are trying to\r\n",
      "\u001B[31m   \u001B[0m install.\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m If you wish to install a non-Arch-packaged Python package,\r\n",
      "\u001B[31m   \u001B[0m create a virtual environment using 'python -m venv path/to/venv'.\r\n",
      "\u001B[31m   \u001B[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m If you wish to install a non-Arch packaged Python application,\r\n",
      "\u001B[31m   \u001B[0m it may be easiest to use 'pipx install xyz', which will manage a\r\n",
      "\u001B[31m   \u001B[0m virtual environment for you. Make sure you have python-pipx\r\n",
      "\u001B[31m   \u001B[0m installed via pacman.\r\n",
      "\r\n",
      "\u001B[1;35mnote\u001B[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\r\n",
      "\u001B[1;36mhint\u001B[0m: See PEP 668 for the detailed specification.\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T15:33:51.952434Z",
     "start_time": "2024-05-04T15:33:51.943740Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
   ],
   "metadata": {
    "id": "MGqkUX2XiVLA",
    "ExecuteTime": {
     "end_time": "2024-05-04T15:33:53.841652Z",
     "start_time": "2024-05-04T15:33:53.034329Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "#@markdown We implemented some functions to visualize the hand landmark detection results. <br/> Run the following cell to activate the functions.\n",
    "\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "\n",
    "MARGIN = 10  # pixels\n",
    "FONT_SIZE = 1\n",
    "FONT_THICKNESS = 1\n",
    "HANDEDNESS_TEXT_COLOR = (88, 205, 54) # vibrant green\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  hand_landmarks_list = detection_result.hand_landmarks\n",
    "  handedness_list = detection_result.handedness\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected hands to visualize.\n",
    "  for idx in range(len(hand_landmarks_list)):\n",
    "    hand_landmarks = hand_landmarks_list[idx]\n",
    "    handedness = handedness_list[idx]\n",
    "\n",
    "    # Draw the hand landmarks.\n",
    "    hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    hand_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "    ])\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "      annotated_image,\n",
    "      hand_landmarks_proto,\n",
    "      solutions.hands.HAND_CONNECTIONS,\n",
    "      solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "      solutions.drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "    # Get the top left corner of the detected hand's bounding box.\n",
    "    height, width, _ = annotated_image.shape\n",
    "    x_coordinates = [landmark.x for landmark in hand_landmarks]\n",
    "    y_coordinates = [landmark.y for landmark in hand_landmarks]\n",
    "    text_x = int(min(x_coordinates) * width)\n",
    "    text_y = int(min(y_coordinates) * height) - MARGIN\n",
    "\n",
    "\n",
    "    print(handedness[0].category_name)\n",
    "\n",
    "    print(\"x-coords:\", x_coordinates)\n",
    "    print(\"y-coords:\", y_coordinates)\n",
    "\n",
    "    # Draw handedness (left or right hand) on the image.\n",
    "    cv2.putText(annotated_image, f\"{handedness[0].category_name}\",\n",
    "                (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "  return annotated_image"
   ],
   "metadata": {
    "id": "L9My1LlXiVW-",
    "ExecuteTime": {
     "end_time": "2024-05-04T15:33:59.004122Z",
     "start_time": "2024-05-04T15:33:56.531502Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "!wget -q -O image.jpg https://storage.googleapis.com/mediapipe-tasks/hand_landmarker/woman_hands.jpg\n",
    "\n",
    "\n",
    "img = cv2.imread(\"image.jpg\")\n",
    "print(img.shape)\n",
    "\n",
    "!wget -q -O image.jpg https://kentuckycounselingcenter.com/wp-content/uploads/2022/01/thinking-man-gf9b9e7a8b_1920.png\n",
    "\n",
    "\n",
    "import cv2\n",
    "img = cv2.imread('image.jpg')\n",
    "# bgr_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "# Display the BGR image\n",
    "print(img.shape)\n",
    "img = cv2.resize(img, (960, 640))\n",
    "cv2.imwrite(\"image.jpg\", img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# img = cv2.imread(\"image.jpg\")\n",
    "# cv2_imshow(img)\n",
    "\n",
    "# img.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Z3gSc837icJM",
    "outputId": "0f1dcca4-f85f-4890-c64f-57c0acfb2e6f",
    "ExecuteTime": {
     "end_time": "2024-05-04T15:34:58.606589Z",
     "start_time": "2024-05-04T15:34:57.644095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 640, 3)\n",
      "(960, 640, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "HzHN9v_Ki_QO"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 1: Import the necessary modules.\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "# STEP 2: Create an HandLandmarker object.\n",
    "base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "options = vision.HandLandmarkerOptions(base_options=base_options,\n",
    "                                       num_hands=2)\n",
    "detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "# STEP 3: Load the input image.\n",
    "image = mp.Image.create_from_file(\"image.jpg\")\n",
    "\n",
    "# STEP 4: Detect hand landmarks from the input image.\n",
    "detection_result = detector.detect(image)\n",
    "\n",
    "# STEP 5: Process the classification result. In this case, visualize it.\n",
    "annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "3NuFKQVriVjX",
    "outputId": "f5a478dd-b614-47cb-e168-0b443a8bfde4",
    "ExecuteTime": {
     "end_time": "2024-05-04T15:35:08.550033Z",
     "start_time": "2024-05-04T15:35:07.983288Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714836908.214958  790397 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1714836908.226080  791599 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.6-arch1.2), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "/home/bourrasque/Documents/GDSCHack/.venv/lib/python3.9/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NormalizedLandmarkList' object has no attribute 'MergeFrom'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m image \u001B[38;5;241m=\u001B[39m mp\u001B[38;5;241m.\u001B[39mImage\u001B[38;5;241m.\u001B[39mcreate_from_file(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# STEP 4: Detect hand landmarks from the input image.\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m detection_result \u001B[38;5;241m=\u001B[39m \u001B[43mdetector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# STEP 5: Process the classification result. In this case, visualize it.\u001B[39;00m\n\u001B[1;32m     19\u001B[0m annotated_image \u001B[38;5;241m=\u001B[39m draw_landmarks_on_image(image\u001B[38;5;241m.\u001B[39mnumpy_view(), detection_result)\n",
      "File \u001B[0;32m~/Documents/GDSCHack/.venv/lib/python3.9/site-packages/mediapipe/tasks/python/vision/hand_landmarker.py:411\u001B[0m, in \u001B[0;36mHandLandmarker.detect\u001B[0;34m(self, image, image_processing_options)\u001B[0m\n\u001B[1;32m    408\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_packets[_HAND_LANDMARKS_STREAM_NAME]\u001B[38;5;241m.\u001B[39mis_empty():\n\u001B[1;32m    409\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m HandLandmarkerResult([], [], [])\n\u001B[0;32m--> 411\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_build_landmarker_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_packets\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GDSCHack/.venv/lib/python3.9/site-packages/mediapipe/tasks/python/vision/hand_landmarker.py:192\u001B[0m, in \u001B[0;36m_build_landmarker_result\u001B[0;34m(output_packets)\u001B[0m\n\u001B[1;32m    190\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m proto \u001B[38;5;129;01min\u001B[39;00m hand_landmarks_proto_list:\n\u001B[1;32m    191\u001B[0m   hand_landmarks \u001B[38;5;241m=\u001B[39m landmark_pb2\u001B[38;5;241m.\u001B[39mNormalizedLandmarkList()\n\u001B[0;32m--> 192\u001B[0m   \u001B[43mhand_landmarks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMergeFrom\u001B[49m(proto)\n\u001B[1;32m    193\u001B[0m   hand_landmarks_list \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    194\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m hand_landmark \u001B[38;5;129;01min\u001B[39;00m hand_landmarks\u001B[38;5;241m.\u001B[39mlandmark:\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NormalizedLandmarkList' object has no attribute 'MergeFrom'"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Vu--ThYSig0L"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
